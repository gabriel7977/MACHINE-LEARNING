---
title: "W4 project ML"
author: "Gabriel Olivares G"
date: "1/5/2021"
output:
  pdf_document: default
  html_document:
    keep_md: yes
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## WEEK 4 MACHINE LEARNING PROJECT ASSIGNMENT

### Executive summary
In this document I present the results of the week 4 project assignment.
The goal of the project is to estimate a model that can be used to predict the 
manner in which the participants of an experiment called 
"Human Activity Recognition" (HAR) have performed the exercise.
("The classe column" in the Data frame).(*)  

According to this source the data was collected in the following manner: 
Six young health participants were asked to perform one set of 10 repetitions of
the Unilateral Dumbbell Biceps Curl in five different fashions: 
Class A: according to the specification; Class B:  throwing the elbows to the
front; Class C: lifting the dumbbell only halfway; Class D: lowering the dumbbell 
only halfway; and, Class E: throwing the hips to the front.
Class A corresponds to the specified execution of the exercise, while the other
4 classes correspond to common mistakes. 

(*) The data for this project come from this source, whose authors kindly made it 
public --"avaliable) for use"-- in the Coursera Machine Learning module: 
http://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har

The details of the experiment, the data frame and the metadata of this 
experiment can be consulted in the following paper: 
Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. 
Qualitative Activity Recognition of Weight Lifting Exercises.
Proceedings of 4th International Conference in Cooperation with SIGCHI 
(Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013.

## Downloading data

```{r}
setwd("C:/Users/gog/OneDrive/Documentos/R/COURSERA/Machine learning/w4 project")
library(readr); library(tidyverse)
pml.testing<-as_tibble(
  read.csv("~/R/COURSERA/Machine learning/w4 project/pml-testing.csv"))
pml.training <- as_tibble(
  read.csv("~/R/COURSERA/Machine learning/w4 project/pml-training.csv"))
dim(pml.training);dim(pml.testing)
```

## Cleaning data for model estimation: training and test set
```{r}
sum(colSums(is.na(pml.training))==0)
sum(colSums(is.na(pml.testing))==0)
#> Number of complete cases (all variables)
sum(complete.cases(pml.training))
sum(complete.cases(pml.testing))
```
As you may notice, There exists a lot of variables that have missing 
values. Fortunately this columns seem to be distribution parameters (mean, std,
Kurtosis; etc).

### Selection of columns to be used
```{r}
col_names_tr<-names(pml.training)[colSums(is.na(pml.training))>0]
train_clean<-pml.training[,colSums(is.na(pml.training))==0]
col_names_test<-names(pml.testing)[colSums(is.na(pml.testing))>0]
test_clean<-pml.testing[,colSums(is.na(pml.testing))==0]
# As the testing data set has less  variables than the training I selected the 
# ones that are common in both data sets. 
train_clean<-pml.training[,colSums(is.na(pml.testing))==0]
train_clean$classe<-as.factor(train_clean$classe)
# Clean Data bases
sum(complete.cases(train_clean))
table(train_clean$user_name,train_clean$classe)
sum(complete.cases(test_clean))
rm(pml.testing,pml.training)
```
## Model estimation
```{r}
# Model Estimation
library(caret); library(randomForest)
## Training and testing data sets for model estimation
set.seed(142857)
inTrain<-createDataPartition(y=train_clean$classe,p=0.7,list=FALSE)
training=train_clean[inTrain,][,8:60]
testing=train_clean[-inTrain,] [8:60]
dim(training); dim(testing)
```
# CART Model (rpart)
```{r}
ctrl=trainControl(method="cv") 
mod_rpart = train(classe~.,training, method="rpart")
print(mod_rpart)
# Predict outcomes using the CART model
pred_rpart <- predict(mod_rpart, testing)
# Show prediction result
(confM_rpart <- confusionMatrix(testing$classe, pred_rpart))
```
# Random Forest Model
```{r}
mod_rf = randomForest(classe~.,training)
print(mod_rf)
# Predict outcomes using the testing set with the Random Forest Model
pred_rf <- predict(mod_rf, testing)
# Prediction result with the Random Forest Model
(confM_rf <- confusionMatrix(testing$classe, pred_rf))
```
## Prediction
According to the accuracy results the "best" model among the two that were 
estimated is the Random Forest. The accuracy is 99.5% vs. 51% in the CART model
The final prediction on the test data frame (validation set?) is the 
following:
```{r}
predict(mod_rf,test_clean)
```
